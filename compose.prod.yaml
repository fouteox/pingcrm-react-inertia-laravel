x-logging: &default-logging
  driver: 'json-file'
  options:
    max-size: "50m"
    max-file: 6
x-network: &default-network
  internal:
x-base: &base
  depends_on:
    mariadb:
      condition: service_healthy
    valkey:
      condition: service_healthy
    ssr:
      condition: service_healthy
  image: ${IMAGE_NAME:-app}:latest
  env_file:
    - .env.production
  ulimits:
    nofile:
      soft: 20000
      hard: 40000
  security_opt:
    - no-new-privileges:true
  volumes:
    - 'storage_public:/var/www/html/storage/app/public'
    - 'storage_logs:/var/www/html/storage/logs'
  logging: *default-logging
  restart: always

services:
  app:
    <<: *base
    build:
      target: app
    command: ["php", "/var/www/html/artisan", "octane:start", "--server=frankenphp", "--port=8000"]
    stop_signal: SIGTERM
    environment:
      AUTORUN_ENABLED: true
      AUTORUN_LARAVEL_MIGRATION_MODE: fresh
      AUTORUN_LARAVEL_MIGRATION_SEED: true
      INERTIA_SSR_URL: http://ssr:13714
      INERTIA_SSR_ENSURE_BUNDLE_EXISTS: false
      PHP_OPCACHE_ENABLE: "1"
    networks:
      - internal
      - proxy
    healthcheck:
      test: ["CMD", "healthcheck-octane"]
      start_period: 10s
    labels:
      traefik.enable: true
      traefik.http.routers.pingcrm.rule: Host(`${APP_HOST}`)
#      traefik.http.routers.pingcrm.entrypoints: websecure
#      traefik.http.routers.pingcrm.tls: true
#      traefik.http.routers.pingcrm.tls.certresolver: letsencrypt-cloudflare
      traefik.http.services.pingcrm.loadbalancer.server.port: 8000
      # Health check
      traefik.http.services.pingcrm.loadbalancer.healthcheck.path: "/up"
      traefik.http.services.pingcrm.loadbalancer.healthcheck.interval: "30s"
      traefik.http.services.pingcrm.loadbalancer.healthcheck.timeout: "5s"
      traefik.http.services.pingcrm.loadbalancer.healthcheck.scheme: "http"

  horizon:
    <<: *base
    command: ["php", "/var/www/html/artisan", "horizon"]
    stop_signal: SIGTERM
    networks: *default-network
    depends_on:
      app:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "healthcheck-horizon"]
      start_period: 10s

  scheduler:
    <<: *base
    command: ["php", "/var/www/html/artisan", "schedule:work"]
    stop_signal: SIGTERM
    networks: *default-network
    depends_on:
      app:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "healthcheck-schedule"]
      start_period: 10s

  reverb:
    <<: *base
    command: ["php", "/var/www/html/artisan", "reverb:start", "--port=8080"]
    stop_signal: SIGTERM
    networks:
      - internal
      - proxy
    depends_on:
      app:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "healthcheck-reverb"]
      start_period: 10s
    labels:
      traefik.enable: true
      traefik.http.routers.reverb.rule: Host(`${APP_HOST}`) && (PathPrefix(`/app`) || PathPrefix(`/apps`))
#      traefik.http.routers.reverb.entrypoints: websecure
#      traefik.http.routers.reverb.tls: true
#      traefik.http.routers.reverb.tls.certresolver: letsencrypt-cloudflare
      traefik.http.services.reverb.loadbalancer.server.port: 8080

  ssr:
    image: ${IMAGE_NAME:-app}:ssr
    build:
      target: ssr
    security_opt:
      - no-new-privileges:true
    networks: *default-network
    logging: *default-logging
    restart: always
    healthcheck:
      test: ["CMD", "node", "-e", "fetch('http://localhost:13714/health').then(r => process.exit(r.ok ? 0 : 1)).catch(() => process.exit(1))"]
      start_period: 5s
      interval: 30s
      timeout: 10s
      retries: 3

  valkey:
    image: 'valkey/valkey:alpine'
    ulimits:
      nofile:
        soft: 20000
        hard: 40000
    command: [ "valkey-server", "--requirepass", "${REDIS_PASSWORD}", "--maxmemory", "2gb" ]
    security_opt:
      - no-new-privileges:true
    environment:
      REDIS_PASSWORD: "${REDIS_PASSWORD}"
    volumes:
      - 'stack-valkey:/data'
      - 'backup_dumps:/dumps'
    logging: *default-logging
    networks: *default-network
    healthcheck:
      test: [ "CMD", "valkey-cli", "-a", "${REDIS_PASSWORD}", "ping" ]
      retries: 3
      timeout: 5s
    labels:
      - docker-volume-backup.archive-pre=/bin/sh -c 'valkey-cli -a $$REDIS_PASSWORD BGSAVE && sleep 2 && cp /data/dump.rdb /dumps/valkey.rdb'
    restart: always

  mariadb:
    image: mariadb:11.4
    ulimits:
      nofile:
        soft: 20000
        hard: 40000
    security_opt:
      - no-new-privileges:true
    environment:
      MARIADB_RANDOM_ROOT_PASSWORD: "1"
      MARIADB_DATABASE: "${DB_DATABASE}"
      MARIADB_USER: "${DB_USERNAME}"
      MARIADB_PASSWORD: "${DB_PASSWORD}"
    volumes:
      - 'stack-mariadb:/var/lib/mysql'
      - 'backup_dumps:/dumps'
    networks: *default-network
    logging: *default-logging
    healthcheck:
      test: [ "CMD", "healthcheck.sh", "--connect", "--innodb_initialized" ]
      start_period: 10s
      interval: 10s
      timeout: 5s
      retries: 3
    labels:
      - docker-volume-backup.archive-pre=/bin/sh -c 'mariadb-dump -u $$MARIADB_USER -p$$MARIADB_PASSWORD --single-transaction $$MARIADB_DATABASE > /dumps/mariadb.sql'
    restart: always

  backup:
    image: offen/docker-volume-backup:v2
    security_opt:
      - no-new-privileges:true
    environment:
      AWS_S3_BUCKET_NAME: "${BACKUP_S3_BUCKET}"
      AWS_S3_PATH: "${BACKUP_S3_PATH}"
      AWS_ACCESS_KEY_ID: "${BACKUP_AWS_ACCESS_KEY_ID}"
      AWS_SECRET_ACCESS_KEY: "${BACKUP_AWS_SECRET_ACCESS_KEY}"
      AWS_ENDPOINT: "${BACKUP_AWS_ENDPOINT}"
      BACKUP_CRON_EXPRESSION: "0 3 * * *"
      BACKUP_RETENTION_DAYS: "${BACKUP_RETENTION_DAYS:-7}"
    volumes:
      - backup_dumps:/backup/dumps:ro
      - storage_logs:/backup/logs:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
    networks: *default-network
    logging: *default-logging
    restart: always

networks:
  internal:
  proxy:
    external: true

volumes:
  storage_public:
  storage_logs:
  stack-valkey:
  stack-mariadb:
  backup_dumps:
